{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "import math\n",
    "\n",
    "class binCalculator:\n",
    "    class Parameters:\n",
    "        def __init__(self, parent):\n",
    "            self.name = None\n",
    "            self.parent = parent\n",
    "            self.bin_mask = (0, 0, 0, 0)\n",
    "            self.bin_size = 50\n",
    "            self.bin_offset = 0\n",
    "            self.background_begin_time_ms = 0\n",
    "            self.background_end_time_ms = 0.5\n",
    "            self.background_average_level = '4trace'\n",
    "            self.background_D_mode = 'equal'\n",
    "            self.noisechannel_substraction = False\n",
    "            self.noisechannel = []\n",
    "            self.group_size = 20\n",
    "            self.sum_shot = True\n",
    "            self.sum_channel = False\n",
    "            self.ACMEIII_header_purge = True\n",
    "            self.file_dtype = 'int16'\n",
    "            self.trace_already_summed = True\n",
    "            self.channel_weight =[-0.03963429, -0.03918644, -0.03918644, -0.04009249, -0.03986207,\n",
    "       -0.03853333, -0.0387486 , -0.0387486]\n",
    "            self.total_timestamps = 175000\n",
    "            self.info_header_length = 4\n",
    "\n",
    "        def _load_parameters_from_json(self, parameter_file_path):\n",
    "            try:\n",
    "                with open(parameter_file_path, 'r') as f:\n",
    "                    param_dict = json.load(f)\n",
    "                \n",
    "                for key, value in param_dict.items():\n",
    "                    if hasattr(self, key) and value is not None:\n",
    "                        setattr(self, key, value)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Parameter file {parameter_file_path} not found, using default values.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON file {parameter_file_path}, using default values.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    class BinResults:\n",
    "        def __init__(self):\n",
    "            self.name = None\n",
    "            self.A = None\n",
    "            self.N = None\n",
    "            self.dA2_from_photon = None\n",
    "            self.dA2_from_fitting = None\n",
    "            self.chi_square = None\n",
    "            self.red_chi_square = None\n",
    "            self.N0 = None\n",
    "            self.A0 = None\n",
    "            self.N1 = None\n",
    "            self.A1 = None\n",
    "            self.shot_yield = None\n",
    "            self.e_A = None\n",
    "            self.e_N = None\n",
    "            self.bin_pair_inspection_data = None\n",
    "            self.x_mask = None  # pre swap x_mask\n",
    "            self.y_mask = None # pre swap y_mask\n",
    "            self.swap_xy = None\n",
    "            self.F = None\n",
    "\n",
    "    def __init__(self, binary_file_path, parameter_file_path, df_slice):\n",
    "        # Initialization\n",
    "        self.raw_data = None\n",
    "        self.data = None\n",
    "        self.name = None\n",
    "        self.file_name = None\n",
    "        self.background_subtracted_data = None\n",
    "        self.ungrouped_Fx = None\n",
    "        self.ungrouped_Fy = None\n",
    "        self.ungrouped_N_total = None\n",
    "        self.ungrouped_asymmetry = None\n",
    "        self.grouped_Fx = None\n",
    "        self.grouped_Fy =  None\n",
    "        self.grouped_F = None  # Fx - Fy\n",
    "        self.grouped_N_total = None\n",
    "        self.grouped_asymmetry = None\n",
    "        self.ungrouped_Fx_before_substraction = None\n",
    "        self.ungrouped_Fy_before_substraction = None\n",
    "        self.df = df_slice\n",
    "        self.binary_file_path = binary_file_path\n",
    "        self.parameter_file_path = parameter_file_path\n",
    "        self.binresult = self.BinResults()\n",
    "        self.parameter = self.Parameters(self)\n",
    "        self.parameter._load_parameters_from_json(self.parameter_file_path)\n",
    "        try:\n",
    "            self.swap_xy = False if self.df['Polarization Switching XY Swapped'].dropna().mode()[0] == 0 else True\n",
    "        except:\n",
    "            self.swap_xy = False\n",
    "        self.binresult.swap_xy = self.swap_xy\n",
    "        # print('swap_xy', self.swap_xy)\n",
    "    \n",
    "    def default_pipeline(self):\n",
    "        # 1. Load the binary data\n",
    "        self._load_binary_data(time_total_timestamps=self.parameter.total_timestamps)\n",
    "\n",
    "        self._photon_conversion()\n",
    "\n",
    "        self._apply_binning(time_total_timestamps=self.parameter.total_timestamps)\n",
    "\n",
    "        self._calculate_Fx_Fy()\n",
    "\n",
    "        self._bg_substraction()\n",
    "\n",
    "        self._calculate_asymmetry()\n",
    "\n",
    "        self._group_asymmetry()\n",
    "\n",
    "        self._group_linear_fit()\n",
    "\n",
    "        self._chi_square()\n",
    "\n",
    "        self._calculate_shot_yield()\n",
    "\n",
    "    def smooth_data_step(data, step_size=5):\n",
    "        smoothed_data = np.array([\n",
    "            np.mean(data[max(0, i - step_size // 2):min(len(data), i + step_size // 2 + 1)]) \n",
    "            for i in range(len(data))\n",
    "        ])\n",
    "        return smoothed_data\n",
    "\n",
    "    def _load_binary_data(self, time_total_timestamps = 175000):\n",
    "        \"\"\" load in the binary file as unbinned data (before scaling to photon number) into self.raw_data \"\"\"\n",
    "        def _header_purging(data,info_header_length = 4,channel_total_number = 8, time_total_timestamps= time_total_timestamps):\n",
    "            reshaped_data = data.reshape(-1,info_header_length+channel_total_number*time_total_timestamps)\n",
    "            truncated_segments = reshaped_data[:, info_header_length:]\n",
    "            purged_data = truncated_segments.flatten()\n",
    "            return purged_data\n",
    "\n",
    "        def _fluorescent_to_data(data, purge = True, trace_already_summed = True, info_header_length = 4, time_total_timestamps = time_total_timestamps):\n",
    "            channel_total_number = 8\n",
    "            time_total_timestamps = time_total_timestamps\n",
    "            if purge == True:\n",
    "                shot_number = int(len(data)/(channel_total_number*time_total_timestamps+ info_header_length))\n",
    "                purged_data = _header_purging(data, info_header_length=info_header_length, time_total_timestamps=time_total_timestamps)\n",
    "            else:\n",
    "                shot_number = int(len(data)/(channel_total_number*time_total_timestamps))\n",
    "                purged_data = data\n",
    "            if trace_already_summed is False:\n",
    "                trace_number = shot_number//25\n",
    "                mat = purged_data.reshape(trace_number, 25 , channel_total_number,-1)\n",
    "            else:\n",
    "                trace_number = shot_number\n",
    "                mat = purged_data.reshape(trace_number, 1 , channel_total_number, -1)\n",
    "            return mat\n",
    "\n",
    "        if self.parameter.file_dtype == 'int16':\n",
    "            dtype = np.int16\n",
    "        elif self.parameter.file_dtype == 'int32':\n",
    "            dtype = np.int32\n",
    "        elif self.parameter.file_dtype == 'float32':\n",
    "            dtype = np.float32\n",
    "        elif self.parameter.file_dtype == 'float64':\n",
    "            dtype = np.float64\n",
    "\n",
    "        with open(self.binary_file_path, \"rb\") as file:\n",
    "            self.data = np.fromfile(self.binary_file_path, dtype=dtype)\n",
    "        self.file_name = os.path.basename(self.binary_file_path)\n",
    "        self.name, _ = os.path.splitext(self.file_name)\n",
    "        self.binresult.name = self.name\n",
    "        self.raw_data = _fluorescent_to_data(self.data, self.parameter.ACMEIII_header_purge, self.parameter.trace_already_summed, self.parameter.info_header_length, time_total_timestamps=self.parameter.total_timestamps)\n",
    "        self.raw_data = self.raw_data.astype(np.float64)\n",
    "\n",
    "    def _photon_conversion(self):\n",
    "        self.data = self.raw_data*(np.array(self.parameter.channel_weight).reshape(1,1,8,1))\n",
    "\n",
    "    def _apply_binning(self, time_total_timestamps = 175000):\n",
    "        bin_offset = self.parameter.bin_offset\n",
    "        while bin_offset<0:\n",
    "            bin_offset = bin_offset + self.parameter.bin_size\n",
    "        while bin_offset>=self.parameter.bin_size:\n",
    "            bin_offset = bin_offset - self.parameter.bin_size\n",
    "        adjusted_size = time_total_timestamps - (time_total_timestamps - bin_offset) % self.parameter.bin_size\n",
    "        if self.parameter.trace_already_summed is False:\n",
    "            self.binned_data = self.data[:,:,:,bin_offset:adjusted_size].reshape(self.data.shape[0],25,8,-1,self.parameter.bin_size)\n",
    "        else:\n",
    "            self.binned_data = self.data[:,:,:,bin_offset:adjusted_size].reshape(self.data.shape[0],1,8,-1,self.parameter.bin_size)\n",
    "\n",
    "    def _calculate_Fx_Fy(self):\n",
    "        def _generate_mask(x_gap_left=0,x_gap_right=0,y_gap_left=0,y_gap_right=0,bin_size=50, swap_xy = False):\n",
    "            x_mask = np.concatenate([np.zeros(x_gap_left),np.ones(bin_size//2-x_gap_left-x_gap_right),np.zeros(x_gap_right),np.zeros(bin_size//2)])\n",
    "            y_mask = np.concatenate([np.zeros(bin_size//2),np.zeros(y_gap_left),np.ones(bin_size//2-y_gap_left-y_gap_right),np.zeros(y_gap_right)])\n",
    "            if swap_xy:\n",
    "                return y_mask,x_mask\n",
    "            return x_mask,y_mask\n",
    "\n",
    "        # Use the bin_mask to separate Fx and Fy from data\n",
    "        x_mask, y_mask = _generate_mask(*self.parameter.bin_mask, self.parameter.bin_size, self.swap_xy)\n",
    "        self.binresult.x_mask = x_mask\n",
    "        self.binresult.y_mask = y_mask\n",
    "        ungrouped_Fx = np.tensordot(self.binned_data, x_mask, axes=([4], [0]))\n",
    "        ungrouped_Fy = np.tensordot(self.binned_data, y_mask, axes=([4], [0]))\n",
    "\n",
    "        if self.parameter.sum_shot:\n",
    "            ungrouped_Fx = ungrouped_Fx.sum(axis = (1),keepdims = True)\n",
    "            ungrouped_Fy = ungrouped_Fy.sum(axis = (1),keepdims = True)\n",
    "        if self.parameter.sum_channel:\n",
    "            ungrouped_Fx = ungrouped_Fx.sum(axis = (2),keepdims = True)\n",
    "            ungrouped_Fy = ungrouped_Fy.sum(axis = (2),keepdims = True)\n",
    "\n",
    "        self.ungrouped_Fx_before_substraction = ungrouped_Fx\n",
    "        self.ungrouped_Fy_before_substraction = ungrouped_Fy\n",
    "        \n",
    "        if self.parameter.noisechannel_substraction:\n",
    "            if len(self.parameter.noisechannel) > 0:\n",
    "                background_channel = self.parameter.noisechannel\n",
    "                remaining_channel = [i for i in range(8) if i not in background_channel]\n",
    "                predicted_bg = np.zeros(self.ungrouped_Fy_before_substraction.mean(axis = 2, keepdims = True).shape)\n",
    "                for trace in range(self.ungrouped_Fy_before_substraction.shape[0]):\n",
    "                    for shot in range(self.ungrouped_Fy_before_substraction.shape[1]):\n",
    "                        if len(background_channel) > 1:\n",
    "                            predicted_bg[trace, shot, 0 , :] = (binCalculator.smooth_data_step(self.ungrouped_Fy_before_substraction[trace, shot, background_channel, :].mean(axis = 0), 300) + binCalculator.smooth_data_step(self.ungrouped_Fx_before_substraction[trace, shot, background_channel, :].mean(axis = 0), 300))/2.0\n",
    "                        else:\n",
    "                            predicted_bg[trace, shot, 0 , :] = (binCalculator.smooth_data_step(self.ungrouped_Fy_before_substraction[trace, shot, background_channel[0], :], 300) + binCalculator.smooth_data_step(self.ungrouped_Fx_before_substraction[trace, shot, background_channel[0], :], 300))/2.0\n",
    "                self.ungrouped_Fx_before_substraction = self.ungrouped_Fx_before_substraction[:,:,remaining_channel,:] - predicted_bg\n",
    "                self.ungrouped_Fy_before_substraction = self.ungrouped_Fy_before_substraction[:,:,remaining_channel,:] - predicted_bg\n",
    "        else:\n",
    "            if len(self.parameter.noisechannel) > 0:\n",
    "                background_channel = self.parameter.noisechannel\n",
    "                remaining_channel = [i for i in range(8) if i not in background_channel]\n",
    "                self.ungrouped_Fx_before_substraction = self.ungrouped_Fx_before_substraction[:,:,remaining_channel,:]\n",
    "                self.ungrouped_Fy_before_substraction = self.ungrouped_Fy_before_substraction[:,:,remaining_channel,:]\n",
    "            \n",
    "\n",
    "    def _bg_substraction(self):\n",
    "        background_begin_bin_index = int(math.floor((self.parameter.background_begin_time_ms*1000000//80)//self.parameter.bin_size))\n",
    "        background_end_bin_index = int(math.floor((self.parameter.background_end_time_ms*1000000//80)//self.parameter.bin_size))\n",
    "\n",
    "        if self.parameter.background_average_level == 'shot':\n",
    "            bgx = self.ungrouped_Fx_before_substraction[:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = 3, keepdims = True).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 3)\n",
    "            bgy = self.ungrouped_Fy_before_substraction[:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = 3, keepdims = True).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 3)\n",
    "        if self.parameter.background_average_level == 'trace':\n",
    "            bgx = self.ungrouped_Fx_before_substraction[:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,3), keepdims = True).repeat(self.ungrouped_Fx_before_substraction.shape[1],axis = 1).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 3)\n",
    "            bgy = self.ungrouped_Fy_before_substraction[:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,3), keepdims = True).repeat(self.ungrouped_Fy_before_substraction.shape[1],axis = 1).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 3)\n",
    "        if self.parameter.background_average_level == 'block':\n",
    "            bgx = self.ungrouped_Fx_before_substraction[:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (0,1,3), keepdims = True).repeat(self.ungrouped_Fx_before_substraction.shape[0],axis = 0).repeat(self.ungrouped_Fx_before_substraction.shape[1],axis = 1).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 3)\n",
    "            bgy = self.ungrouped_Fy_before_substraction[:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (0,1,3), keepdims = True).repeat(self.ungrouped_Fy_before_substraction.shape[0],axis = 0).repeat(self.ungrouped_Fy_before_substraction.shape[1],axis = 1).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 3)\n",
    "        if self.parameter.background_average_level == 'none':\n",
    "            bgx = 0\n",
    "            bgy = 0\n",
    "        if self.parameter.background_average_level == '2trace':\n",
    "            bgx = self.ungrouped_Fx_before_substraction.reshape(-1,2,*self.ungrouped_Fx_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(2,axis = 1).repeat(self.ungrouped_Fx_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fx_before_substraction.shape)\n",
    "            bgy = self.ungrouped_Fy_before_substraction.reshape(-1,2,*self.ungrouped_Fy_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(2,axis = 1).repeat(self.ungrouped_Fy_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fy_before_substraction.shape)\n",
    "        if self.parameter.background_average_level == '4trace':\n",
    "            bgx = self.ungrouped_Fx_before_substraction.reshape(-1,4,*self.ungrouped_Fx_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(4,axis = 1).repeat(self.ungrouped_Fx_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fx_before_substraction.shape)\n",
    "            bgy = self.ungrouped_Fy_before_substraction.reshape(-1,4,*self.ungrouped_Fy_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(4,axis = 1).repeat(self.ungrouped_Fy_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fy_before_substraction.shape)\n",
    "        if self.parameter.background_average_level == '8trace':\n",
    "            bgx = self.ungrouped_Fx_before_substraction.reshape(-1,8,*self.ungrouped_Fx_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(8,axis = 1).repeat(self.ungrouped_Fx_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fx_before_substraction.shape)\n",
    "            bgy = self.ungrouped_Fy_before_substraction.reshape(-1,8,*self.ungrouped_Fy_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(8,axis = 1).repeat(self.ungrouped_Fy_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fy_before_substraction.shape)\n",
    "        if self.parameter.background_average_level == '16trace':\n",
    "            bgx = self.ungrouped_Fx_before_substraction.reshape(-1,16,*self.ungrouped_Fx_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(16,axis = 1).repeat(self.ungrouped_Fx_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fx_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fx_before_substraction.shape)\n",
    "            bgy = self.ungrouped_Fy_before_substraction.reshape(-1,16,*self.ungrouped_Fy_before_substraction.shape[1:])[:,:,:,:,background_begin_bin_index:background_end_bin_index].mean(axis = (1,2,4), keepdims = True).repeat(16,axis = 1).repeat(self.ungrouped_Fy_before_substraction.shape[1],axis = 2).repeat(self.ungrouped_Fy_before_substraction.shape[3],axis = 4).reshape(self.ungrouped_Fy_before_substraction.shape)\n",
    "            \n",
    "        if self.parameter.background_D_mode == 'equal':\n",
    "            bg = (bgx + bgy) / 2.0\n",
    "            bgx = bg\n",
    "            bgy = bg\n",
    "\n",
    "        self.bgx = bgx\n",
    "        self.bgy = bgy\n",
    "        self.ungrouped_Fx = self.ungrouped_Fx_before_substraction - bgx\n",
    "        self.ungrouped_Fy = self.ungrouped_Fy_before_substraction - bgy\n",
    "\n",
    "        # for bin_pair_inspection_slice\n",
    "        bgz = self.binned_data[:,:,:,background_begin_bin_index:background_end_bin_index,:].mean(axis = (1,3), keepdims = True).repeat(self.binned_data.shape[1],axis = 1).repeat(self.binned_data.shape[3],axis = 3)\n",
    "        self.binresult.bin_pair_inspection_data = (self.binned_data - bgz).mean(axis = (0,1,2))\n",
    "\n",
    "\n",
    "    def _calculate_asymmetry(self):\n",
    "        self.ungrouped_N_total = self.ungrouped_Fx + self.ungrouped_Fy\n",
    "        self.ungrouped_asymmetry = (self.ungrouped_Fx - self.ungrouped_Fy) / self.ungrouped_N_total\n",
    "\n",
    "\n",
    "    def _group_asymmetry(self):\n",
    "        group_size = self.parameter.group_size\n",
    "\n",
    "        truncated_bin_size = self.ungrouped_N_total.shape[-1] - (self.ungrouped_N_total.shape[-1] )%group_size\n",
    "        number_of_group = truncated_bin_size//group_size\n",
    "        new_dimension = (*self.ungrouped_N_total.shape[:-1], number_of_group, group_size)\n",
    "        self.grouped_Fx = self.ungrouped_Fx[..., :truncated_bin_size].reshape(new_dimension)\n",
    "        self.grouped_Fy =  self.ungrouped_Fy[..., :truncated_bin_size].reshape(new_dimension)\n",
    "        self.grouped_F = self.grouped_Fx - self.grouped_Fy\n",
    "        self.binresult.F = self.grouped_F.sum(axis = -1)\n",
    "        self.grouped_N_total =  self.ungrouped_N_total[..., :truncated_bin_size].reshape(new_dimension)\n",
    "        self.grouped_asymmetry =  self.ungrouped_asymmetry[..., :truncated_bin_size].reshape(new_dimension)\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(nopython=True, parallel=True)\n",
    "    def _linear_fit_5d_numba(data,x):\n",
    "        traces, shots, channels, groups, withingroups = data.shape\n",
    "        B0 = np.zeros((traces, shots, channels, groups))\n",
    "        B1 = np.zeros((traces, shots, channels, groups))\n",
    "        err = np.zeros((traces, shots, channels, groups, withingroups))\n",
    "        for trace in prange(traces):\n",
    "            for shot in range(shots):\n",
    "                for channel in range(channels):\n",
    "                    for group in range(groups):\n",
    "                        y = data[trace, shot, channel, group, :]\n",
    "                        # Calculating sums needed for the coefficients\n",
    "                        Sxx = np.sum(x * x)\n",
    "                        Sxy = np.sum(x * y)\n",
    "                        Sx = np.sum(x)\n",
    "                        Sy = np.sum(y)\n",
    "                        # Slope and intercept calculations\n",
    "                        denominator = withingroups * Sxx - Sx ** 2\n",
    "                        if denominator != 0:\n",
    "                            slope = (withingroups * Sxy - Sx * Sy) / denominator\n",
    "                            intercept = (Sy - slope * Sx) / withingroups\n",
    "                        else:\n",
    "                            slope = 0.0\n",
    "                            intercept = np.mean(y)  # or any fallback logic\n",
    "                        # Store results\n",
    "                        B0[trace, shot, channel, group] = intercept\n",
    "                        B1[trace, shot, channel, group] = slope\n",
    "                        # Calculate residuals\n",
    "                        predicted_y = intercept + slope * x\n",
    "                        err[trace, shot, channel, group, :] = y - predicted_y\n",
    "        return B0, B1, err\n",
    "\n",
    "    def _group_linear_fit(self):\n",
    "        t = np.arange(self.parameter.group_size)\n",
    "        self.binresult.A0, self.binresult.A1, self.binresult.e_A = binCalculator._linear_fit_5d_numba(self.grouped_asymmetry, t)\n",
    "        self.binresult.N0, self.binresult.N1, self.binresult.e_N = binCalculator._linear_fit_5d_numba(self.grouped_N_total, t)\n",
    "\n",
    "    def _chi_square(self):\n",
    "        self.binresult.A = np.zeros(self.binresult.A0.shape)\n",
    "        self.binresult.N = np.zeros(self.binresult.N0.shape)\n",
    "        self.binresult.dA2_from_fitting = np.zeros(self.binresult.A0.shape)\n",
    "        self.binresult.dA2_from_photon = np.zeros(self.binresult.A0.shape)\n",
    "\n",
    "        for trace in range(self.binresult.N0.shape[0]):\n",
    "            for shot in range(self.binresult.N0.shape[1]):\n",
    "                for channel in range(self.binresult.N0.shape[2]):\n",
    "                    for group in range(self.binresult.N0.shape[3]):\n",
    "                        self.binresult.N[trace, shot, channel, group] = self.parameter.group_size* (self.binresult.N0[trace, shot, channel, group] + self.binresult.N1[trace, shot, channel, group] * (self.parameter.group_size - 1)/2)\n",
    "                        self.binresult.A[trace, shot, channel, group]  = self.binresult.A0[trace, shot, channel, group] + self.binresult.A1[trace, shot, channel, group] * (self.parameter.group_size - 1)/2\n",
    "                        self.binresult.dA2_from_fitting[trace, shot, channel, group] = 1/(self.parameter.group_size)*1/(self.parameter.group_size -2)*np.sum((self.binresult.e_A[trace, shot, channel, group, :])**2)\n",
    "                        self.binresult.dA2_from_photon[trace, shot, channel, group] = (1 - (self.binresult.A0[trace, shot, channel, group] + self.binresult.A1[trace, shot, channel, group]*(self.parameter.group_size-1)/2) ** 2)/(self.parameter.group_size*(self.binresult.N0[trace, shot, channel, group]+self.binresult.N1[trace, shot, channel, group]*((self.parameter.group_size-1)/2)))\n",
    "        self.binresult.red_chi_square = self.binresult.dA2_from_fitting / self.binresult.dA2_from_photon\n",
    "        self.binresult.chi_square = self.binresult.red_chi_square * (self.parameter.group_size - 2)\n",
    "\n",
    "    def _calculate_shot_yield(self):\n",
    "        self.binresult.shot_yield = self.ungrouped_N_total.sum(axis = (2,3))\n",
    "\n",
    "    def saveBinResults(self, folder_path):\n",
    "        # Ensure the directory exists before writing the file\n",
    "        if not os.path.exists(folder_path):\n",
    "            try:\n",
    "                os.makedirs(folder_path)  # Create the directory if it does not exist\n",
    "            except OSError as e:\n",
    "                print(f\"Bin Calculator: Error creating directory {folder_path}: {e}\")\n",
    "                return\n",
    "\n",
    "        # Generate a file name based on your logic (example: timestamp + .pkl)\n",
    "        file_name = \"binresult_\" + self.binresult.name +\".pkl\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                # Save only the bin results without additional dictionary layers\n",
    "                pickle.dump(self.binresult, f)\n",
    "            # print(f\"Bin result saved: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Bin Calculator: Error saving results: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['Polarization Switching XY Swapped'] = [0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = binCalculator(r\"c:\\ACMEdata\\data0010.1464\\0010.1464.0000.0000.bin\", r\"../templates/acmeiii/offsettrace/offsettrace1.json\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.default_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
