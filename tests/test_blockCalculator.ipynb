{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edmAnalyzer import binCalculator, binCutter, binVisualizer, hh, parityStateTransform, combine_switches\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from cryptography.hazmat.primitives import serialization, hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import padding\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "class blockCalculator:\n",
    "    class blind_object:\n",
    "        def __init__(self, blind_value_in_rad_s, blind_id):\n",
    "            self._blind_value_in_rad_s = blind_value_in_rad_s\n",
    "            self.blind_id = blind_id\n",
    "\n",
    "        def __str__(self):\n",
    "            return f\"************rad/s, blind name: {self.blind_id}\"\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"************rad/s, blind name: {self.blind_id}\"\n",
    "\n",
    "    class Parameters:\n",
    "        def __init__(self):\n",
    "            self.full_waveplate_dither_range_in_deg= 2\n",
    "            self.error_propagation_method= \"simple\"\n",
    "\n",
    "        def _load_parameters_from_json(self, parameter_file_path):\n",
    "            try:\n",
    "                with open(parameter_file_path, 'r') as f:\n",
    "                    param_dict = json.load(f)\n",
    "                \n",
    "                for key, value in param_dict.items():\n",
    "                    if hasattr(self, key) and value is not None:\n",
    "                        setattr(self, key, value)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Block Parameter file {parameter_file_path} not found, using default values.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Block: Error decoding JSON file {parameter_file_path}, using default values.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Block: Unexpected error: {e}\")\n",
    "\n",
    "    class BlockResults:\n",
    "\n",
    "        class Blinded:\n",
    "            def __init__(self):\n",
    "                self.blind_id = None\n",
    "                self.result = {}\n",
    "                self.result_sipmsum = {}    \n",
    "                self.result_summary = {}\n",
    "\n",
    "        class Unblinded:\n",
    "            def __init__(self):\n",
    "                self.result = {}\n",
    "                self.result_sipmsum = {}\n",
    "                self.result_summary = {}\n",
    "\n",
    "        def __init__(self):\n",
    "            self.blinded = self.Blinded()\n",
    "            self.__unblinded = self.Unblinded()\n",
    "            self.block_string = None\n",
    "            self.blockcut_left = None\n",
    "            self.blockcut_right = None\n",
    "            self.parity_labels = None\n",
    "            self.state_labels = None\n",
    "            self.red_chi_square_trace_shot_A = None\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, blockpara_json_path = None, binresults_path_list = None, bincutresult_path_list = None, blockresult_path = None, df = None, phi_B_over_tau = None, blind_path = None):\n",
    "        self.P, self.parity_labels, self.switch_labels = parityStateTransform(channelName= ['N','E','B'])\n",
    "        self.blind = None\n",
    "        self.read_blind(blind_path)\n",
    "        self.parameters = self.Parameters()\n",
    "        self.parameters._load_parameters_from_json(blockpara_json_path)\n",
    "        self.blockresult = self.BlockResults()\n",
    "        self.blockresult.blinded.blind_id = self.blind.blind_id\n",
    "        self.blockresult.parity_labels = self.parity_labels\n",
    "        self.blockresult.state_labels = self.switch_labels\n",
    "        self.binresults_path_list = binresults_path_list\n",
    "        self.bincutresult_path_list = bincutresult_path_list\n",
    "        self.blockresult_path = blockresult_path\n",
    "        self.df = df\n",
    "        self.blockcut_mask = None\n",
    "        self.blockcut_left = None\n",
    "        self.blockcut_right = None\n",
    "        self.t = -180/2/np.pi/self.parameters.full_waveplate_dither_range_in_deg\n",
    "        self.phi_B_over_tau = phi_B_over_tau\n",
    "        self.aggregated_traces = {}\n",
    "        self._load_binresults()\n",
    "        self._load_bincutresults()\n",
    "        self._pipeline_simple()\n",
    "        self.save_result()\n",
    "\n",
    "    def read_blind(self, folder_path):\n",
    "        # Define the file paths\n",
    "        blind_bytes_path = os.path.join(folder_path, 'blind_bytes.txt')\n",
    "        private_key_path = os.path.join(folder_path, 'private_key.txt')\n",
    "\n",
    "        # Try to read the blind bytes from the txt file\n",
    "        try:\n",
    "            with open(blind_bytes_path, 'rb') as f:\n",
    "                extracted_bytes = f.read()\n",
    "        except FileNotFoundError as e:\n",
    "            raise Exception(f\"Failed to open blind bytes file: {blind_bytes_path}\") from e\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while reading the blind bytes file: {blind_bytes_path}\") from e\n",
    "\n",
    "        # Try to read the private key from the file\n",
    "        try:\n",
    "            with open(private_key_path, 'rb') as f:\n",
    "                private_key_data = f.read()\n",
    "        except FileNotFoundError as e:\n",
    "            raise Exception(f\"Failed to open private key file: {private_key_path}\") from e\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while reading the private key file: {private_key_path}\") from e\n",
    "\n",
    "        # Skip the first line of the private key and extract the last four characters of the second line\n",
    "        try:\n",
    "            private_key_lines = private_key_data.splitlines()\n",
    "            key_id_start = private_key_lines[1][-4:].decode('utf-8', errors='ignore')\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Failed to extract the last four letters from the second line of the private key\") from e\n",
    "\n",
    "        # Try to deserialize the private key\n",
    "        try:\n",
    "            private_key = serialization.load_pem_private_key(\n",
    "                private_key_data,\n",
    "                password=None\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Failed to deserialize the private key\") from e\n",
    "\n",
    "        # Try to decrypt the blind using the private key\n",
    "        try:\n",
    "            decrypted_blind = private_key.decrypt(\n",
    "                extracted_bytes,\n",
    "                padding.OAEP(\n",
    "                    mgf=padding.MGF1(algorithm=hashes.SHA256()),\n",
    "                    algorithm=hashes.SHA256(),\n",
    "                    label=None\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Failed to decrypt the blind value\") from e\n",
    "\n",
    "        # Try to convert the decrypted blind back to a double\n",
    "        try:\n",
    "            blind_value_in_rad_s = np.frombuffer(decrypted_blind, dtype=np.float64)[0]\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Failed to convert decrypted blind to float64\") from e\n",
    "\n",
    "        # Create the blind ID using the folder name and the last four letters of the second line of the private key\n",
    "        folder_name = os.path.basename(folder_path)\n",
    "        blind_id = f\"{folder_name}-{key_id_start}\"\n",
    "\n",
    "        # Return the blind_object\n",
    "        self.blind =  blockCalculator.blind_object(blind_value_in_rad_s, blind_id)\n",
    "\n",
    "    def _diag_along_axis(A, axis):\n",
    "        shape = A.shape\n",
    "        new_shape = list(shape)\n",
    "        new_shape.insert(axis, shape[axis])\n",
    "        \n",
    "        diag_mask = np.eye(shape[axis], dtype=A.dtype)\n",
    "        expanded_diag_shape = [1] * (len(shape) + 1)\n",
    "        expanded_diag_shape[axis] = shape[axis]\n",
    "        expanded_diag_shape[axis + 1] = shape[axis]\n",
    "        diag_mask = diag_mask.reshape(expanded_diag_shape)\n",
    "        \n",
    "        expanded_A_shape = list(shape)\n",
    "        expanded_A_shape.insert(axis, 1)\n",
    "        expanded_A = A.reshape(expanded_A_shape)\n",
    "        \n",
    "        B = diag_mask * expanded_A\n",
    "        \n",
    "        return B\n",
    "\n",
    "    def _extract_diagonal_along_axes(matrix, axis):\n",
    "        \"\"\"\n",
    "        Extract the diagonal elements along the specified axis and the next axis,\n",
    "        and bring the diagonal axis to the position of the specified axis.\n",
    "\n",
    "        Parameters:\n",
    "        matrix (np.ndarray): The input n-dimensional array.\n",
    "        axis (int): The axis along which to extract diagonals with the next axis.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: The resultant array after extracting diagonals.\n",
    "        \"\"\"\n",
    "        if axis < 0 or axis >= matrix.ndim - 1:\n",
    "            raise ValueError(\"Axis out of bounds or too high for the given matrix dimensions.\")\n",
    "        \n",
    "        # Extract the diagonal along the specified axis and the next axis\n",
    "        diag_matrix = np.diagonal(matrix, axis1=axis, axis2=axis + 1)\n",
    "        \n",
    "        # Move the diagonal axis to the original position of the specified axis\n",
    "        new_axes_order = list(range(diag_matrix.ndim))\n",
    "        new_axes_order.insert(axis, new_axes_order.pop(-1))\n",
    "        \n",
    "        result = np.transpose(diag_matrix, new_axes_order)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _calculate_center_of_mass(arr):\n",
    "        # Get the shape of the array except the last dimension\n",
    "        indices = np.arange(arr.shape[-1])  # Create an array of indices for the last dimension\n",
    "        \n",
    "        # Multiply the values in the array by the index along the last dimension\n",
    "        weighted_values = arr * indices\n",
    "        \n",
    "        # Sum the weighted values and the original values along the last dimension\n",
    "        sum_weighted = np.sum(weighted_values, axis=-1, keepdims=True)  # keepdims=True to maintain the last dimension\n",
    "        sum_values = np.sum(arr, axis=-1, keepdims=True)  # keepdims=True to maintain the last dimension\n",
    "        \n",
    "        # Calculate the center of mass\n",
    "        center_of_mass = sum_weighted / (sum_values + 1e-10)  # To avoid division by zero\n",
    "        \n",
    "        return center_of_mass\n",
    "\n",
    "    def _sipm_vector(arr):\n",
    "        sipm_matrix = np.array([[ 1,  1,  1],\n",
    "                  [-1,  1,  1],\n",
    "                  [ 1, -1,  1],\n",
    "                  [-1, -1,  1],\n",
    "                  [ 1,  1, -1],\n",
    "                  [-1,  1, -1],\n",
    "                  [ 1, -1, -1],\n",
    "                  [-1, -1, -1]])\n",
    "        sipm_matrix = sipm_matrix[0:arr.shape[-2]]\n",
    "        summed_vector  = np.swapaxes(np.tensordot(arr, sipm_matrix, axes = (-2,0)),-2,-1)\n",
    "        summed_signal = arr.sum(axis = -2, keepdims=True)\n",
    "        result = np.nan_to_num(np.divide(summed_vector,summed_signal))\n",
    "        return result[...,[0],:], result[...,[1],:], result[...,[2],:]\n",
    "\n",
    "    def _propagate_error_bar(A, dA2, axis_to_take_average, nan = False):\n",
    "        if nan:\n",
    "            if isinstance(axis_to_take_average, int):\n",
    "                axis_to_take_average = (axis_to_take_average,)\n",
    "\n",
    "            selected_dimension = [A.shape[i] for i in axis_to_take_average]\n",
    "\n",
    "            if np.prod(selected_dimension) == 1:\n",
    "                A_mean = A\n",
    "                dA_mean_square_scaled = dA2\n",
    "                red_chi_square = np.full(A.shape, np.nan)\n",
    "                dA_mean_square_unscaled = dA2\n",
    "                return A_mean, dA_mean_square_unscaled, dA_mean_square_scaled, red_chi_square\n",
    "\n",
    "            weights = 1 / dA2\n",
    "            A_mean = np.nansum(A * weights, axis=axis_to_take_average, keepdims=True) / np.nansum(weights, axis=axis_to_take_average, keepdims=True)\n",
    "\n",
    "            dA_mean_square_unscaled = 1 / np.nansum(weights, axis=axis_to_take_average, keepdims=True)\n",
    "\n",
    "            total_number_of_points = np.nanprod([A.shape[axis] for axis in axis_to_take_average])\n",
    "            residuals = (A - A_mean)**2\n",
    "            red_chi_square = np.nansum(residuals / dA2, axis=axis_to_take_average, keepdims=True) / (total_number_of_points - 1)\n",
    "\n",
    "            dA_mean_square_scaled = dA_mean_square_unscaled * red_chi_square\n",
    "\n",
    "            return A_mean, dA_mean_square_unscaled, dA_mean_square_scaled, red_chi_square\n",
    "        \n",
    "        else:\n",
    "\n",
    "            if isinstance(axis_to_take_average, int):\n",
    "                axis_to_take_average = (axis_to_take_average,)\n",
    "\n",
    "            selected_dimension = [A.shape[i] for i in axis_to_take_average]\n",
    "\n",
    "            if np.prod(selected_dimension) == 1:\n",
    "                A_mean = A\n",
    "                dA_mean_square_scaled = dA2\n",
    "                red_chi_square = np.full(A.shape, np.nan)\n",
    "                dA_mean_square_unscaled = dA2\n",
    "                return A_mean, dA_mean_square_unscaled, dA_mean_square_scaled, red_chi_square\n",
    "\n",
    "            weights = 1 / dA2\n",
    "            A_mean = np.sum(A * weights, axis=axis_to_take_average, keepdims=True) / np.sum(weights, axis=axis_to_take_average, keepdims=True)\n",
    "\n",
    "            dA_mean_square_unscaled = 1 / np.sum(weights, axis=axis_to_take_average, keepdims=True)\n",
    "\n",
    "            total_number_of_points = np.prod([A.shape[axis] for axis in axis_to_take_average])\n",
    "            residuals = (A - A_mean)**2\n",
    "            red_chi_square = np.sum(residuals / dA2, axis=axis_to_take_average, keepdims=True) / (total_number_of_points - 1)\n",
    "\n",
    "            dA_mean_square_scaled = dA_mean_square_unscaled * red_chi_square\n",
    "\n",
    "            return A_mean, dA_mean_square_unscaled, dA_mean_square_scaled, red_chi_square\n",
    "        \n",
    "    def _load_bincutresults(self):\n",
    "        try:\n",
    "            grand_mask_list = []\n",
    "            grand_left_list = []\n",
    "            grand_right_list = []\n",
    "\n",
    "            # Iterate over the paths in bincutresult_path_list\n",
    "            for path in self.bincutresult_path_list:\n",
    "                # Load the .pkl file\n",
    "                with open(path, 'rb') as file:\n",
    "                    bincutresult = pickle.load(file)\n",
    "                    \n",
    "                    # Append grand_mask, grand_left, grand_right from each pkl file to their respective lists\n",
    "                    grand_mask_list.append(bincutresult.grand_mask)\n",
    "                    grand_left_list.append(bincutresult.grand_left)\n",
    "                    grand_right_list.append(bincutresult.grand_right)\n",
    "            \n",
    "            # Calculate element-wise product for grand_mask\n",
    "            self.blockcut_mask = np.prod(grand_mask_list, axis=0)\n",
    "\n",
    "            # Calculate the maximum for grand_left\n",
    "            self.blockcut_left = np.max(grand_left_list, axis=0)\n",
    "            self.blockresult.blockcut_left = self.blockcut_left\n",
    "\n",
    "            # Calculate the minimum for grand_right\n",
    "            self.blockcut_right = np.min(grand_right_list, axis=0)\n",
    "            self.blockresult.blockcut_right = self.blockcut_right\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading bincut result files: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error in _load_bincutresults: {e}\")\n",
    "\n",
    "    def _load_binresults(self):\n",
    "\n",
    "        # Sort the binresults_path_list lexicographically\n",
    "        self.binresults_path_list.sort()\n",
    "\n",
    "        # Regex to extract run, sequence, block, and trace_offset from file names\n",
    "        pattern = r\"binresult_(\\d{4})\\.(\\d{4})\\.(\\d{4})\\.(\\d{4})\\.pkl\"\n",
    "\n",
    "        # Initialize aggregated_traces if not already done\n",
    "        if 'A' not in self.aggregated_traces:\n",
    "            self.aggregated_traces['A'] = {}\n",
    "        if 'dA2' not in self.aggregated_traces:\n",
    "            self.aggregated_traces['dA2'] = {}\n",
    "        if 'N' not in self.aggregated_traces:\n",
    "            self.aggregated_traces['N'] = {}\n",
    "        if 'F' not in self.aggregated_traces:\n",
    "            self.aggregated_traces['F'] = {}\n",
    "\n",
    "        # Iterate over the sorted binresults_path_list\n",
    "        for path in self.binresults_path_list:\n",
    "            match = re.search(pattern, path)\n",
    "            if not match:\n",
    "                print(f\"Filename format error in {path}\")\n",
    "                continue\n",
    "            \n",
    "            run, sequence, block, trace_offset = map(int, match.groups())\n",
    "\n",
    "            # Load the binresult from the file\n",
    "            with open(path, 'rb') as file:\n",
    "                binresult = pickle.load(file)\n",
    "\n",
    "                # Extract arrays\n",
    "                A_array = binresult.A  # Assume A is an np array\n",
    "                dA2_array = binresult.dA2_from_photon  # Assume this is an np array\n",
    "                N_array = binresult.N  # Assume this is an np array\n",
    "\n",
    "                # Iterate over the traces in A_array (axis=0)\n",
    "                for idx in range(A_array.shape[0]):\n",
    "                    trace = trace_offset + idx\n",
    "                    \n",
    "                    # Look up the corresponding row in the dataframe based on run, sequence, block, and trace\n",
    "                    df_row = self.df[(self.df['run'] == run) & \n",
    "                                    (self.df['sequence'] == sequence) & \n",
    "                                    (self.df['block'] == block) & \n",
    "                                    (self.df['trace'] == trace)]\n",
    "                    \n",
    "                    if df_row.empty:\n",
    "                        print(f\"No matching data for run={run}, sequence={sequence}, block={block}, trace={trace}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract the N, E, B, theta, phi_B_over_tau columns\n",
    "                    N_val = df_row['N'].values[0]\n",
    "                    E_val = df_row['E'].values[0]\n",
    "                    B_val = df_row['B'].values[0]\n",
    "                    theta_val = df_row['theta'].values[0]\n",
    "                    \n",
    "                    state_tuple = (N_val, E_val, B_val, theta_val)\n",
    "\n",
    "                    # Initialize dictionary entries if not yet present\n",
    "                    if state_tuple not in self.aggregated_traces['A']:\n",
    "                        self.aggregated_traces['A'][state_tuple] = []\n",
    "                    if state_tuple not in self.aggregated_traces['dA2']:\n",
    "                        self.aggregated_traces['dA2'][state_tuple] = []\n",
    "                    if state_tuple not in self.aggregated_traces['N']:\n",
    "                        self.aggregated_traces['N'][state_tuple] = []\n",
    "                    if state_tuple not in self.aggregated_traces['F']:\n",
    "                        self.aggregated_traces['F'][state_tuple] = []\n",
    "\n",
    "                    # Append data to the respective state in aggregated_traces\n",
    "                    self.aggregated_traces['A'][state_tuple].append(A_array[idx])\n",
    "                    self.aggregated_traces['dA2'][state_tuple].append(dA2_array[idx])\n",
    "                    self.aggregated_traces['N'][state_tuple].append(N_array[idx])\n",
    "                    self.aggregated_traces['F'][state_tuple].append(binresult.F[idx])\n",
    "\n",
    "        # Now, stack the lists into arrays along axis=0 for each state in aggregated_traces\n",
    "        for quantity in ['A', 'dA2', 'N', 'F']:\n",
    "            for state_tuple, data_list in self.aggregated_traces[quantity].items():\n",
    "                self.aggregated_traces[quantity][state_tuple] = np.stack(data_list, axis=0)\n",
    "\n",
    "        for quantity in ['A', 'dA2', 'N', 'F']:\n",
    "            sorted_states = sorted(self.aggregated_traces[quantity].keys(), reverse=True)\n",
    "            sorted_arrays = [self.aggregated_traces[quantity][state] for state in sorted_states]\n",
    "            self.aggregated_traces[quantity] = np.stack(sorted_arrays, axis=0)\n",
    "        self.blockresult.block_string = str(run).zfill(4)+'.'+str(sequence).zfill(4)+'.'+str(block).zfill(4)\n",
    "\n",
    "    def _pipeline_simple(self):\n",
    "        \"\"\" In this calculation pipeline, no correlation between anything is considered.\"\"\"\n",
    "        A_raw, dA2_raw, _, self.blockresult.red_chi_square_trace_shot_A  = blockCalculator._propagate_error_bar(self.aggregated_traces['A'], self.aggregated_traces['dA2'], axis_to_take_average=(1,2))\n",
    "        N_raw= self.aggregated_traces['N'].sum(axis = (1,2),  keepdims=True)\n",
    "        F_raw = self.aggregated_traces['F'].sum(axis = (1,2),  keepdims=True)\n",
    "        # Calculate phi_state and C_state\n",
    "\n",
    "        A_raw = A_raw.reshape(-1,2,*A_raw.shape[1:])\n",
    "        dA2_raw = dA2_raw.reshape(-1,2,*dA2_raw.shape[1:])\n",
    "        N_raw = N_raw.reshape(-1,2,*N_raw.shape[1:])\n",
    "        F_raw = F_raw.reshape(-1,2,*F_raw.shape[1:])\n",
    "\n",
    "        N_state = N_raw[:,0,...] + N_raw[:,1,...]\n",
    "\n",
    "        N_state_summary = N_state[..., self.blockcut_left:self.blockcut_right].sum(axis = -1, keepdims=True)\n",
    "        xsipm_state_summary,ysipm_state_summary,zsipm_state_summary = blockCalculator._sipm_vector(N_state_summary)\n",
    "\n",
    "\n",
    "        envelop_phi_state_all_sipm = (np.diff(N_state.sum(axis = -2, keepdims = True), axis = -1)/N_state.sum(axis = -2, keepdims = True)[...,1:])/20/2/2/2\n",
    "        envelop_phi_state = (np.diff(N_state, axis = -1)/N_state[...,1:])/20/2/2/2\n",
    "        center_of_mass_state = blockCalculator._calculate_center_of_mass(N_state)\n",
    "        xsipm_state,ysipm_state,zsipm_state = blockCalculator._sipm_vector(N_state)\n",
    "        sipmratio_state = N_state/N_state.sum(axis = -2, keepdims=True)\n",
    "\n",
    "        N = np.tensordot(self.P, N_state, axes = (1,0))\n",
    "        envelop_phi_all_sipm = np.tensordot(self.P, envelop_phi_state_all_sipm, axes = (1,0))\n",
    "        envelop_phi = np.tensordot(self.P, envelop_phi_state, axes = (1,0))\n",
    "\n",
    "        xsipm = np.tensordot(self.P, xsipm_state, axes = (1,0))\n",
    "        ysipm = np.tensordot(self.P, ysipm_state, axes = (1,0))\n",
    "        zsipm = np.tensordot(self.P, zsipm_state, axes = (1,0))\n",
    "        sipmratio = np.tensordot(self.P, sipmratio_state, axes = (1,0))    \n",
    "\n",
    "\n",
    "        center_of_mass = np.tensordot(self.P, center_of_mass_state, axes = (1,0))\n",
    "\n",
    "        C_state = self.t / 2 * (A_raw[:,0,...] - A_raw[:,1,...])\n",
    "        s = np.sign(C_state)\n",
    "        A_state = s / 2 * (A_raw[:,0,...] + A_raw[:,1,...])\n",
    "        Ap_state = 1/2 * (A_raw[:,0,...] + A_raw[:,1,...])\n",
    "\n",
    "        Am_state = 1/2 * (A_raw[:,0,...] - A_raw[:,1,...]) \n",
    "        FA_state = s/2 * (F_raw[:,0,...] + F_raw[:,1,...])\n",
    "        FC_state = self.t / 2 * (F_raw[:,0,...] - F_raw[:,1,...])\n",
    "\n",
    "        dAp2_state = 1.0/4.0 * (dA2_raw[:,0,...] + dA2_raw[:,1,...])\n",
    "        dAm2_state = 1.0/4.0 * (dA2_raw[:,0,...] + dA2_raw[:,1,...])    \n",
    "        \n",
    "        dA2_state = (s / 2) ** 2 * (dA2_raw[:,0,...] + dA2_raw[:,1,...])\n",
    "        dC2_state = (self.t / 2) ** 2 * (dA2_raw[:,0,...] + dA2_raw[:,1,...])\n",
    "        covAC_state = s * self.t/ 4 *  (dA2_raw[:,0,...] - dA2_raw[:,1,...])\n",
    "        #phi_state = 1 / 2 * A_state / np.abs(C_state) * (1 + d_C_state_2 / C_state**2) - 1 / 2 * 4 * covA_state_C_state * s / C_state**2\n",
    "        phi_state = 1 / 2 * A_state / np.abs(C_state) * 1\n",
    "        #dphi2_state = phi_state**2 * (d_C_state_2 / C_state**2 + d_A_state_2 / A_state**2) - phi_state * 8 * s * covA_state_C_state / C_state**2\n",
    "        dphi2_state = phi_state**2 * (dC2_state / C_state**2 + dA2_state / A_state**2)\n",
    "\n",
    "        # Calculate parity transformation\n",
    "        dphi2_covariance = np.tensordot(self.P, np.moveaxis(np.tensordot(blockCalculator._diag_along_axis(dphi2_state,0), self.P.T, axes=([1], [0])),-1,1), axes=([1], [0]))\n",
    "        dphi2 = blockCalculator._extract_diagonal_along_axes(np.tensordot(self.P, np.moveaxis(np.tensordot(blockCalculator._diag_along_axis(dphi2_state,0), self.P.T, axes=([1], [0])),-1,1), axes=([1], [0])), 0)\n",
    "        dC2 = blockCalculator._extract_diagonal_along_axes(np.tensordot(self.P, np.moveaxis(np.tensordot(blockCalculator._diag_along_axis(dC2_state,0), self.P.T, axes=([1], [0])),-1,1), axes=([1], [0])), 0)\n",
    "\n",
    "        phi = np.tensordot(self.P, phi_state, axes = (1,0))\n",
    "        C = np.tensordot(self.P, C_state, axes = (1,0))\n",
    "        A = np.tensordot(self.P, A_state, axes = (1,0))\n",
    "        Ap = np.tensordot(self.P, Ap_state, axes = (1,0))\n",
    "\n",
    "        Am = np.tensordot(self.P, Am_state, axes = (1,0))\n",
    "        FA = np.tensordot(self.P, FA_state, axes = (1,0))\n",
    "        FC = np.tensordot(self.P, FC_state, axes = (1,0))\n",
    "        dA2 = blockCalculator._extract_diagonal_along_axes(np.tensordot(self.P, np.moveaxis(np.tensordot(blockCalculator._diag_along_axis(dA2_state,0), self.P.T, axes=([1], [0])),-1,1), axes=([1], [0])), 0)\n",
    "        # Calculate the tau\n",
    "        dAp2 = blockCalculator._extract_diagonal_along_axes(np.tensordot(self.P, np.moveaxis(np.tensordot(blockCalculator._diag_along_axis(dAp2_state,0), self.P.T, axes=([1], [0])),-1,1), axes=([1], [0])), 0)\n",
    "        dAm2 = blockCalculator._extract_diagonal_along_axes(np.tensordot(self.P, np.moveaxis(np.tensordot(blockCalculator._diag_along_axis(dAm2_state,0), self.P.T, axes=([1], [0])),-1,1), axes=([1], [0])), 0)\n",
    "        tau = phi[3].reshape(-1,*phi[3].shape[0:])/self.phi_B_over_tau\n",
    "        dtau2 = dphi2[3].reshape(-1,*dphi2[3].shape[0:])/self.phi_B_over_tau**2\n",
    "\n",
    "        # Calculate the omega \n",
    "\n",
    "        omega = phi/tau\n",
    "        domega2 = omega**2 *(dphi2/phi**2 + dtau2/tau**2)\n",
    "\n",
    "        self.blockresult._BlockResults__unblinded.result = {'N': N, \n",
    "                                                            'C': C, \n",
    "                                                            'A': A,\n",
    "                                                            'dA2': dA2,\n",
    "                                                            'dC2': dC2,\n",
    "                                                            'phi': phi, \n",
    "                                                            'dphi2': dphi2, \n",
    "                                                            'tau': tau, \n",
    "                                                            'dtau2': dtau2, \n",
    "                                                            'omega': omega, \n",
    "                                                            'domega2': domega2,\n",
    "                                                            'xsipm': xsipm,\n",
    "                                                            'ysipm': ysipm,\n",
    "                                                            'zsipm': zsipm,\n",
    "                                                            'sipmratio': sipmratio,\n",
    "                                                            'envelop_phi_all_sipm': envelop_phi_all_sipm,\n",
    "                                                            'envelop_phi': envelop_phi,\n",
    "                                                            'FA': FA,\n",
    "                                                            'FC': FC,\n",
    "\n",
    "                                                            'Ap': Ap,\n",
    "\n",
    "                                                            'Am': Am,\n",
    "\n",
    "                                                            'dAp2': dAp2,\n",
    "\n",
    "                                                            'dAm2': dAm2}\n",
    "                                                            \n",
    "                                                            \n",
    "        \n",
    "        N_sipmsum = N.sum(axis = -2, keepdims=True)\n",
    "        FA_sipmsum = FA.sum(axis = -2, keepdims=True)\n",
    "        FC_sipmsum = FC.sum(axis = -2, keepdims=True)\n",
    "        C_sipmsum, dC2_sipmsum, _, redchigroupC_sipmsum = blockCalculator._propagate_error_bar(C, dC2, axis_to_take_average = -2)\n",
    "        A_sipmsum, dA2_sipmsum, _, redchigroupA_sipmsum = blockCalculator._propagate_error_bar(A, dA2, axis_to_take_average = -2)\n",
    "        phi_sipmsum, dphi2_sipmsum, _, redchigroupphi_sipmsum = blockCalculator._propagate_error_bar(phi, dphi2, axis_to_take_average = -2)\n",
    "        tau_sipmsum, dtau2_sipmsum, _, redchigrouptau_sipmsum = blockCalculator._propagate_error_bar(tau, dtau2, axis_to_take_average = -2)\n",
    "        omega_sipmsum, domega2_sipmsum, _, redchigroupomega_sipmsum = blockCalculator._propagate_error_bar(omega, domega2, axis_to_take_average = -2)\n",
    "        Ap_sipmsum, dAp2_sipmsum, _, _ = blockCalculator._propagate_error_bar(Ap, dAp2, axis_to_take_average = -2)\n",
    "        Am_sipmsum, dAm2_sipmsum, _, _ = blockCalculator._propagate_error_bar(Am, dAm2, axis_to_take_average = -2)\n",
    "\n",
    "        self.blockresult._BlockResults__unblinded.result_sipmsum = {'N_sipmsum': N_sipmsum,\n",
    "                                                                    'C_sipmsum': C_sipmsum,\n",
    "                                                                    'A_sipmsum': A_sipmsum,\n",
    "                                                                    'dA2_sipmsum': dA2_sipmsum,\n",
    "                                                                    'redchigroupA_sipmsum': redchigroupA_sipmsum,\n",
    "                                                                    'dC2_sipmsum': dC2_sipmsum,\n",
    "                                                                    'phi_sipmsum': phi_sipmsum,\n",
    "                                                                    'dphi2_sipmsum': dphi2_sipmsum,\n",
    "                                                                    'tau_sipmsum': tau_sipmsum,\n",
    "                                                                    'dtau2_sipmsum': dtau2_sipmsum,\n",
    "                                                                    'omega_sipmsum': omega_sipmsum,\n",
    "                                                                    'domega2_sipmsum': domega2_sipmsum,\n",
    "                                                                    'redchigroupC_sipmsum': redchigroupC_sipmsum,\n",
    "                                                                    'redchigroupphi_sipmsum': redchigroupphi_sipmsum,\n",
    "                                                                    'redchigrouptau_sipmsum': redchigrouptau_sipmsum,\n",
    "                                                                    'redchigroupomega_sipmsum': redchigroupomega_sipmsum,\n",
    "                                                                    'FA_sipmsum': FA_sipmsum,\n",
    "                                                                    'FC_sipmsum': FC_sipmsum,\n",
    "                                                                    'Ap_sipmsum': Ap_sipmsum,\n",
    "                                                                    'dAp2_sipmsum': dAp2_sipmsum,\n",
    "                                                                    'Am_sipmsum': Am_sipmsum,\n",
    "                                                                    'dAm2_sipmsum': dAm2_sipmsum}\n",
    "\n",
    "        N_summary = N[...,self.blockcut_left:self.blockcut_right].sum(axis = -1, keepdims=True)\n",
    "        FA_summary = FA[...,self.blockcut_left:self.blockcut_right].sum(axis = -1, keepdims=True)\n",
    "        FC_summary = FC[...,self.blockcut_left:self.blockcut_right].sum(axis = -1, keepdims=True)\n",
    "        C_summary, dC2_summary, _, redchigroupC_summary = blockCalculator._propagate_error_bar(C[...,self.blockcut_left:self.blockcut_right], dC2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "        phi_summary, dphi2_summary, _, redchigroupphi_summary = blockCalculator._propagate_error_bar(phi[...,self.blockcut_left:self.blockcut_right], dphi2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "        tau_summary, dtau2_summary, _, redchigrouptau_summary = blockCalculator._propagate_error_bar(tau[...,self.blockcut_left:self.blockcut_right], dtau2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "        omega_summary, domega2_summary, _, redchigroupomega_summary = blockCalculator._propagate_error_bar(omega[...,self.blockcut_left:self.blockcut_right], domega2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "        A_summary, dA2_summary, _, redchigroupA_summary = blockCalculator._propagate_error_bar(A[...,self.blockcut_left:self.blockcut_right], dA2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "        Ap_summary, dAp2_summary, _, _ = blockCalculator._propagate_error_bar(Ap[...,self.blockcut_left:self.blockcut_right], dAp2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "        Am_summary, dAm2_summary, _, _ = blockCalculator._propagate_error_bar(Am[...,self.blockcut_left:self.blockcut_right], dAm2[...,self.blockcut_left:self.blockcut_right], axis_to_take_average = -1)\n",
    "\n",
    "        xsipm_summary = np.tensordot(self.P, xsipm_state_summary, axes = (1,0))\n",
    "        ysipm_summary = np.tensordot(self.P, ysipm_state_summary, axes = (1,0))\n",
    "        zsipm_summary = np.tensordot(self.P, zsipm_state_summary, axes = (1,0))\n",
    "\n",
    "        self.blockresult._BlockResults__unblinded.result_summary = {'N_summary': N_summary, \n",
    "                                               'C_summary': C_summary, \n",
    "                                               'dC2_summary': dC2_summary, \n",
    "                                               'phi_summary': phi_summary, \n",
    "                                               'dphi2_summary': dphi2_summary, \n",
    "                                               'tau_summary': tau_summary, \n",
    "                                               'dtau2_summary': dtau2_summary, \n",
    "                                               'omega_summary': omega_summary, \n",
    "                                               'domega2_summary': domega2_summary,\n",
    "                                               'centerofmass': center_of_mass,\n",
    "                                               'xsipm_summary': xsipm_summary,\n",
    "                                               'ysipm_summary': ysipm_summary,\n",
    "                                               'zsipm_summary': zsipm_summary,\n",
    "                                               'redchigroupC_summary': redchigroupC_summary,\n",
    "                                                'redchigroupphi_summary': redchigroupphi_summary,\n",
    "                                                'redchigrouptau_summary': redchigrouptau_summary,\n",
    "                                                'redchigroupomega_summary': redchigroupomega_summary,\n",
    "                                                'A_summary': A_summary,\n",
    "                                                'dA2_summary': dA2_summary,\n",
    "                                                'redchigroupA_summary': redchigroupA_summary,\n",
    "                                                'FA_summary': FA_summary,\n",
    "                                                'FC_summary': FC_summary,\n",
    "                                                'Ap_summary': Ap_summary,\n",
    "                                                'dAp2_summary': dAp2_summary,\n",
    "                                                'Am_summary': Am_summary,\n",
    "                                                'dAm2_summary': dAm2_summary}\n",
    "        \n",
    "        self.blind_result()\n",
    "        \n",
    "    def blind_result(self):\n",
    "        self.blockresult.blinded.result['N'] = self.blockresult._BlockResults__unblinded.result['N'].copy()\n",
    "        self.blockresult.blinded.result['FA'] = self.blockresult._BlockResults__unblinded.result['FA'].copy()\n",
    "        self.blockresult.blinded.result['FC'] = self.blockresult._BlockResults__unblinded.result['FC'].copy()\n",
    "        self.blockresult.blinded.result['C'] = self.blockresult._BlockResults__unblinded.result['C'].copy()\n",
    "        self.blockresult.blinded.result['dC2'] = self.blockresult._BlockResults__unblinded.result['dC2'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['A'] = self.blockresult._BlockResults__unblinded.result['A'].copy()\n",
    "        self.blockresult.blinded.result['A'][4] = self.blockresult.blinded.result['A'][4] + self.blind._blind_value_in_rad_s * 0.005 * 2\n",
    "\n",
    "        self.blockresult.blinded.result['dA2'] = self.blockresult._BlockResults__unblinded.result['dA2'].copy()\n",
    "        \n",
    "        self.blockresult.blinded.result['Ap'] = self.blockresult._BlockResults__unblinded.result['Ap'].copy()\n",
    "        self.blockresult.blinded.result['dAp2'] = self.blockresult._BlockResults__unblinded.result['dAp2'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['Am'] = self.blockresult._BlockResults__unblinded.result['Am'].copy()\n",
    "        self.blockresult.blinded.result['dAm2'] = self.blockresult._BlockResults__unblinded.result['dAm2'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['phi'] = self.blockresult._BlockResults__unblinded.result['phi'].copy()\n",
    "        self.blockresult.blinded.result['phi'][4] = self.blockresult.blinded.result['phi'][4] + self.blind._blind_value_in_rad_s * self.blockresult._BlockResults__unblinded.result['tau'][0]\n",
    "\n",
    "        self.blockresult.blinded.result['dphi2'] = self.blockresult._BlockResults__unblinded.result['dphi2'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['tau'] = self.blockresult._BlockResults__unblinded.result['tau'].copy()\n",
    "        self.blockresult.blinded.result['dtau2'] = self.blockresult._BlockResults__unblinded.result['dtau2'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['omega'] = self.blockresult._BlockResults__unblinded.result['omega'].copy()\n",
    "        self.blockresult.blinded.result['omega'][4] = self.blockresult.blinded.result['omega'][4] + self.blind._blind_value_in_rad_s\n",
    "\n",
    "        self.blockresult.blinded.result['domega2'] = self.blockresult._BlockResults__unblinded.result['domega2'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['xsipm'] = self.blockresult._BlockResults__unblinded.result['xsipm'].copy()\n",
    "        self.blockresult.blinded.result['ysipm'] = self.blockresult._BlockResults__unblinded.result['ysipm'].copy()\n",
    "        self.blockresult.blinded.result['zsipm'] = self.blockresult._BlockResults__unblinded.result['zsipm'].copy()\n",
    "        self.blockresult.blinded.result['sipmratio'] = self.blockresult._BlockResults__unblinded.result['sipmratio'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result['envelop_phi_all_sipm'] = self.blockresult._BlockResults__unblinded.result['envelop_phi_all_sipm'].copy()\n",
    "        self.blockresult.blinded.result['envelop_phi'] = self.blockresult._BlockResults__unblinded.result['envelop_phi'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['N_summary'] = self.blockresult._BlockResults__unblinded.result_summary['N_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['A_summary'] = self.blockresult._BlockResults__unblinded.result_summary['A_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['A_summary'][4] = self.blockresult.blinded.result_summary['A_summary'][4] + self.blind._blind_value_in_rad_s * 0.005 * 2\n",
    "        self.blockresult.blinded.result_summary['dA2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['dA2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['Ap_summary'] = self.blockresult._BlockResults__unblinded.result_summary['Ap_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['dAp2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['dAp2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['Am_summary'] = self.blockresult._BlockResults__unblinded.result_summary['Am_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['dAm2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['dAm2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['FC_summary'] = self.blockresult._BlockResults__unblinded.result_summary['FC_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['FA_summary'] = self.blockresult._BlockResults__unblinded.result_summary['FA_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['C_summary'] = self.blockresult._BlockResults__unblinded.result_summary['C_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['dC2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['dC2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['phi_summary'] = self.blockresult._BlockResults__unblinded.result_summary['phi_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['phi_summary'][4] = self.blockresult.blinded.result_summary['phi_summary'][4] + self.blind._blind_value_in_rad_s * self.blockresult._BlockResults__unblinded.result_summary['tau_summary'][0]\n",
    "\n",
    "        self.blockresult.blinded.result_summary['dphi2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['dphi2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['tau_summary'] = self.blockresult._BlockResults__unblinded.result_summary['tau_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['dtau2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['dtau2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['omega_summary'] = self.blockresult._BlockResults__unblinded.result_summary['omega_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['omega_summary'][4] = self.blockresult.blinded.result_summary['omega_summary'][4] + self.blind._blind_value_in_rad_s\n",
    "\n",
    "        self.blockresult.blinded.result_summary['domega2_summary'] = self.blockresult._BlockResults__unblinded.result_summary['domega2_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['centerofmass'] = self.blockresult._BlockResults__unblinded.result_summary['centerofmass'].copy()  \n",
    "\n",
    "        self.blockresult.blinded.result_summary['xsipm_summary'] = self.blockresult._BlockResults__unblinded.result_summary['xsipm_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['ysipm_summary'] = self.blockresult._BlockResults__unblinded.result_summary['ysipm_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['zsipm_summary'] = self.blockresult._BlockResults__unblinded.result_summary['zsipm_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_summary['redchigroupC_summary'] = self.blockresult._BlockResults__unblinded.result_summary['redchigroupC_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['redchigroupphi_summary'] = self.blockresult._BlockResults__unblinded.result_summary['redchigroupphi_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['redchigrouptau_summary'] = self.blockresult._BlockResults__unblinded.result_summary['redchigrouptau_summary'].copy()\n",
    "        self.blockresult.blinded.result_summary['redchigroupomega_summary'] = self.blockresult._BlockResults__unblinded.result_summary['redchigroupomega_summary'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_sipmsum['N_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['N_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['A_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['A_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['A_sipmsum'][4] = self.blockresult.blinded.result_sipmsum['A_sipmsum'][4] + self.blind._blind_value_in_rad_s * 0.005 * 2\n",
    "        self.blockresult.blinded.result_sipmsum['dA2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['dA2_sipmsum'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_sipmsum['Ap_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['Ap_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['dAp2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['dAp2_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['Am_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['Am_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['dAm2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['dAm2_sipmsum'].copy()\n",
    "\n",
    "        self.blockresult.blinded.result_sipmsum['C_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['C_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['dC2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['dC2_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['phi_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['phi_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['phi_sipmsum'][4] = self.blockresult.blinded.result_sipmsum['phi_sipmsum'][4] + self.blind._blind_value_in_rad_s * self.blockresult._BlockResults__unblinded.result_sipmsum['tau_sipmsum'][0]\n",
    "        self.blockresult.blinded.result_sipmsum['dphi2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['dphi2_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['tau_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['tau_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['dtau2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['dtau2_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['omega_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['omega_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['omega_sipmsum'][4] = self.blockresult.blinded.result_sipmsum['omega_sipmsum'][4] + self.blind._blind_value_in_rad_s\n",
    "        self.blockresult.blinded.result_sipmsum['domega2_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['domega2_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['FA_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['FA_sipmsum'].copy()\n",
    "        self.blockresult.blinded.result_sipmsum['FC_sipmsum'] = self.blockresult._BlockResults__unblinded.result_sipmsum['FC_sipmsum'].copy()\n",
    "\n",
    "\n",
    "    def save_result(self):\n",
    "        with open(os.path.join(self.blockresult_path, \"blockresult_\" + self.blockresult.block_string)+ '.pkl', 'wb') as f:\n",
    "            pickle.dump(self.blockresult, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\ACME_analysis\\noise1197\\aggregated header.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = blockCalculator(blockpara_json_path =r\"C:\\ACME_analysis\\noise1197\\Analysis Parameters\\blockpara\\simple2.json\",\n",
    "                    binresults_path_list =[r\"C:\\ACME_analysis\\noise1197\\Run Results\\data\\binpara_offset19tracegreed_bincut_frac20_blockpara_simple2_blockcut_blc1_config_0\\Binary Results\\binresult_0009.1197.0000.0000.pkl\"],\n",
    "                    bincutresult_path_list =[r\"C:\\ACME_analysis\\noise1197\\Run Results\\data\\binpara_offset19tracegreed_bincut_frac20_blockpara_simple2_blockcut_blc1_config_0\\Binary Results\\bincutresult_0009.1197.0000.0000.pkl\"],\n",
    "                    blockresult_path =r\"C:\\ACME_analysis\\noise1197\\Run Results\\data\\binpara_offset19tracegreed_bincut_frac20_blockpara_simple2_blockcut_blc1_config_0\\Block Results\", \n",
    "                    df = df, \n",
    "                    phi_B_over_tau = 3.774, \n",
    "                    blind_path = r\"C:\\ACME_analysis\\noise1197\\Blinding Files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
