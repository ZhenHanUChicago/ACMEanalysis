{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust grouped linear fits with IRLS + Huber\n",
    "\n",
    "This notebook performs a robust linear regression for **each unique value** of a column\n",
    "you specify as `line_specifier`. For every group, it fits `y` vs `x` using IRLS with\n",
    "Huber weights, bootstraps the fit parameters, prints the results, and plots each\n",
    "group with a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "# Robust Estimation of means:\n",
    "# Huber weight function\n",
    "\n",
    "def Huber(ei, sigma, s, a=1.345):\n",
    "    w1 = 1 / sigma**2\n",
    "    w2 = 1 / sigma**2 * (a / (np.abs(ei) / (sigma * s)))\n",
    "    weights = np.where(np.abs(ei) <= a * sigma * s, w1, w2)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def ZL_robust_mean(y_, dy_, max_iter=50, tol=1e-6):\n",
    "    \"\"\"Output:\n",
    "    robust mean,\n",
    "    s (a sqrt(reduced chi2-like scale factor), s^2 ~ reduced chi2)\n",
    "    \"\"\"\n",
    "    y = y_\n",
    "    dy = dy_\n",
    "    y_bar = np.average(y, weights=1 / dy**2)\n",
    "    s = 1.0\n",
    "    for _ in range(max_iter):\n",
    "        ei = y - y_bar\n",
    "        w = Huber(ei, dy, s)\n",
    "        y_bar_old = y_bar\n",
    "        y_bar = np.sum(w * y) / np.sum(w)\n",
    "        mad = np.median(np.abs(y - y_bar) / dy)\n",
    "        s = 1.4826 * mad if mad > 0 else 1.0\n",
    "        # tolerance check\n",
    "        if np.abs(y_bar - y_bar_old) < tol * (np.abs(y_bar_old) + 1e-12):\n",
    "            break\n",
    "    return y_bar, s\n",
    "\n",
    "\n",
    "def bootstrap_ZL_robust_mean(y, dy, n_boot=10000, random_state=None):\n",
    "    \"\"\"Output:\n",
    "    mean of bootstrap samples,\n",
    "    std of bootstrap samples,\n",
    "    all bootstrap samples\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    boot_means = np.empty(n_boot)\n",
    "    n = len(y)\n",
    "    for i in tqdm.tqdm(range(n_boot)):\n",
    "        indices = rng.integers(0, n, n)\n",
    "        y_sample = y[indices]\n",
    "        dy_sample = dy[indices]\n",
    "        boot_means[i] = ZL_robust_mean(y_sample, dy_sample)[0]\n",
    "    return boot_means.mean(), boot_means.std(), boot_means\n",
    "\n",
    "\n",
    "# Robust linear regression using IRLS and Huber weights\n",
    "def irls_robust_linear(x, y, dy, max_iter=50, tol=1e-6):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    dy = np.asarray(dy, dtype=float)\n",
    "\n",
    "    # Design matrix: y = a + b x\n",
    "    A = np.vstack([np.ones_like(x), x]).T\n",
    "\n",
    "    # Initial conditions\n",
    "    n = len(y)\n",
    "    s = 1.0\n",
    "    w = np.ones(n) / dy**2\n",
    "\n",
    "    def solve_wls(A, y, weights):\n",
    "        W = np.sqrt(weights)\n",
    "        Aw = A * W[:, None]\n",
    "        yw = y * W\n",
    "        theta, *_ = np.linalg.lstsq(Aw, yw, rcond=None)\n",
    "        return theta\n",
    "\n",
    "    # Initial least squares solution\n",
    "    theta = solve_wls(A, y, w)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        theta_old = theta.copy()\n",
    "        s_old = s\n",
    "\n",
    "        # 1. compute residuals\n",
    "        y_fit = A @ theta\n",
    "        r = y - y_fit\n",
    "\n",
    "        # 2. update scale s using MAD of |r| / dy\n",
    "        mad = np.median(np.abs(r) / dy)\n",
    "        s = 1.4826 * mad if mad > 0 else 1.0\n",
    "\n",
    "        # 3. update weights using Huber function\n",
    "        w = Huber(r, dy, s)\n",
    "\n",
    "        # 4. solve weighted least squares\n",
    "        theta = solve_wls(A, y, w)\n",
    "\n",
    "        # 5. convergence test\n",
    "        if np.linalg.norm(theta - theta_old) < tol * (np.linalg.norm(theta_old) + 1e-12) and \\\n",
    "           abs(s - s_old) < tol * (s_old + 1e-12):\n",
    "            break\n",
    "    beta0, beta1 = theta\n",
    "    return beta0, beta1, s, w\n",
    "\n",
    "\n",
    "def bootstrap_irls(x, y, dy, n_boot=10000, random_state=None):\n",
    "    \"\"\"Bootstrap IRLS over (x, y, dy) triplets.\n",
    "\n",
    "    Returns:\n",
    "        beta0_samples : array of intercepts\n",
    "        beta1_samples : array of slopes\n",
    "        s_samples : array of scale estimates\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    dy = np.asarray(dy)\n",
    "\n",
    "    n = len(x)\n",
    "\n",
    "    beta0_samples = np.empty(n_boot)\n",
    "    beta1_samples = np.empty(n_boot)\n",
    "    s_samples = np.empty(n_boot)\n",
    "\n",
    "    for i in tqdm.tqdm(range(n_boot)):\n",
    "        # 1. Resample indices with replacement\n",
    "        idx = np.random.randint(0, n, size=n)\n",
    "\n",
    "        # 2. Resample triplets together\n",
    "        xb = x[idx]\n",
    "        yb = y[idx]\n",
    "        dyb = dy[idx]\n",
    "\n",
    "        # 3. Run IRLS on bootstrap sample\n",
    "        beta0, beta1, s, _ = irls_robust_linear(xb, yb, dyb)\n",
    "\n",
    "        # 4. Store results\n",
    "        beta0_samples[i] = beta0\n",
    "        beta1_samples[i] = beta1\n",
    "        s_samples[i] = s\n",
    "\n",
    "    return beta0_samples, beta1_samples, s_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User configuration ---\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = r\"C:\\\\ACME_analysis\\\\multiple_results\\\\sequencedf_result\\\\0016.0433_0016.0434_0016.0435_0016.0436_0016.0437_.csv\"\n",
    "\n",
    "# Column names in the dataframe\n",
    "x_name = '1090_STIRAP_ellipticity_angle'\n",
    "y_name = 'omega_E'\n",
    "dy_name = 'uncertainty_omega_E'\n",
    "\n",
    "# Column that specifies which line/group each point belongs to\n",
    "line_specifier = 'line_specifier'  # <-- change this to your actual column name\n",
    "\n",
    "# x-axis unit for printing/labeling\n",
    "x_unit = 'deg'\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.dropna(subset=[x_name, y_name, dy_name, line_specifier])\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {csv_path}\")\n",
    "print(f\"Unique {line_specifier} values: {df[line_specifier].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Robust grouped linear fits and plotting ---\n",
    "\n",
    "unique_groups = df[line_specifier].unique()\n",
    "\n",
    "# For consistent colors across groups\n",
    "cmap = plt.get_cmap('tab10')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "results = []  # store per-group fit results if you want to inspect later\n",
    "\n",
    "for i, group in enumerate(unique_groups):\n",
    "    sub = df[df[line_specifier] == group]\n",
    "    x = sub[x_name].values\n",
    "    y = sub[y_name].values\n",
    "    dy = sub[dy_name].values\n",
    "\n",
    "    if len(sub) < 2:\n",
    "        print(f\"Skipping group {group!r}: not enough points ({len(sub)}) for a linear fit.\")\n",
    "        continue\n",
    "\n",
    "    # Robust IRLS fit\n",
    "    beta0, beta1, s, w = irls_robust_linear(x, y, dy)\n",
    "\n",
    "    # Bootstrap uncertainties\n",
    "    beta0_samples, beta1_samples, s_samples = bootstrap_irls(x, y, dy, n_boot=10000, random_state=None)\n",
    "    se_beta0 = np.std(beta0_samples)\n",
    "    se_beta1 = np.std(beta1_samples)\n",
    "\n",
    "    # Store numerical results\n",
    "    results.append({\n",
    "        'group': group,\n",
    "        'beta0': beta0,\n",
    "        'beta1': beta1,\n",
    "        's': s,\n",
    "        'se_beta0': se_beta0,\n",
    "        'se_beta1': se_beta1\n",
    "    })\n",
    "\n",
    "    # Print results for this group\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(f\"{line_specifier} = {group}\")\n",
    "    print(f\"Intercept: {beta0 * 1e6:.4f} ± {se_beta0 * 1e6:.4f} μrad/s\")\n",
    "    print(f\"Slope:     {beta1 * 1e6:.4f} ± {se_beta1 * 1e6:.4f} μrad/s/{x_unit}\")\n",
    "    print(f\"Scale s:   {s:.4f}\")\n",
    "\n",
    "    # Normalize weights for plotting transparency\n",
    "    w_norm = w / np.max(w)\n",
    "\n",
    "    # Color for this group\n",
    "    color = cmap(i % 10)\n",
    "\n",
    "    # Scatter plot of data points\n",
    "    ax.scatter(\n",
    "        x,\n",
    "        y * 1e6,\n",
    "        s=80,\n",
    "        marker='s',\n",
    "        c=[color],\n",
    "        alpha=0.2 + 0.5 * w_norm,  # weight-dependent transparency\n",
    "        edgecolors='none',\n",
    "        label=f\"{line_specifier} = {group}\"\n",
    "    )\n",
    "\n",
    "    # Best-fit line for this group\n",
    "    x_fit = np.linspace(np.min(x), np.max(x), 100)\n",
    "    y_fit = beta0 + beta1 * x_fit\n",
    "    ax.plot(x_fit, y_fit * 1e6, '-', color=color)\n",
    "\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(f\"{x_name} ({x_unit})\", fontsize=14)\n",
    "ax.set_ylabel(f\"{y_name} (μrad/s)\", fontsize=14)\n",
    "ax.set_title(\"Robust linear fit per group\", fontsize=14)\n",
    "ax.legend(fontsize=9, loc='best')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
